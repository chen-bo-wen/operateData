{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.utils.data.Dataset 介绍与实战:\n",
    "\n",
    "https://blog.csdn.net/weixin_44211968/article/details/123744513\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "import timm\n",
    "\n",
    "# from model import resnet34\n",
    "# 缺少一个 vgg 模型\n",
    "# from model import vgg\n",
    "\n",
    "from torchvision import models\n",
    "\n",
    "def main():\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"using {} device.\".format(device))\n",
    "\n",
    "    # 获取图片路径\n",
    "    data_root = os.path.abspath(os.path.join(os.getcwd(), \"../分类数据\")) \n",
    "    image_path = os.path.join(data_root, \"eggDataset\") \n",
    "    assert os.path.exists(image_path), \"{} path does not exist.\".format(image_path)\n",
    "\n",
    "    # 图像增强\n",
    "    data_transform = {\n",
    "        \"train\": transforms.Compose([transforms.RandomResizedCrop(224),\n",
    "                                     transforms.RandomHorizontalFlip(),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]), \n",
    "        \"val\": transforms.Compose([transforms.Resize(256), # ResNet 正则化参数\n",
    "                                   transforms.CenterCrop(224),\n",
    "                                   transforms.ToTensor(),\n",
    "                                   transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])}\n",
    "    \n",
    "    train_dataset = datasets.ImageFolder(root=os.path.join(image_path, \"train\"),\n",
    "                                         transform=data_transform[\"train\"])\n",
    "\n",
    "    class_list = train_dataset.class_to_idx\n",
    "    print('class_list', class_list)\n",
    "\n",
    "    cla_dict = dict((val, key) for key, val in class_list.items())\n",
    "    # write dict into json file\n",
    "    json_str = json.dumps(cla_dict, indent=4)\n",
    "    with open('class_indices.json', 'w') as json_file:\n",
    "        json_file.write(json_str)\n",
    "    \n",
    "\n",
    "    batch_size = 10\n",
    "    nw = min([os.cpu_count(), batch_size if batch_size > 1 else 0, 8])  # number of workers\n",
    "    print('Using {} dataloader workers every process'.format(nw))\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True,\n",
    "                                               num_workers=nw)\n",
    "\n",
    "\n",
    "    validate_dataset = datasets.ImageFolder(root=os.path.join(image_path, \"val\"),\n",
    "                                           transform=data_transform[\"val\"])\n",
    "\n",
    "    train_num = len(train_dataset)\n",
    "    test_num = len(validate_dataset)\n",
    "    validate_loader = torch.utils.data.DataLoader(validate_dataset,\n",
    "                                                  batch_size=batch_size, shuffle=False,\n",
    "                                                  num_workers=nw)\n",
    "\n",
    "    print(\"using {} images for training, {} images for validation.\".format(train_num, test_num))\n",
    "\n",
    "    net = timm.create_model('efficientnet_b0', pretrained=True)\n",
    "    # net = models.EfficientNet(pretrained=True) # 加载预训练模型\n",
    "    model_name = \"EfficientNet\"\n",
    "    # net = vgg(model_name=model_name, num_classes=4, init_weights=True) # net.fc.in_features, nn.Linear(in_channel, 2) \n",
    "    net.to(device)\n",
    "\n",
    "    # define loss function\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "    # construct an optimizer, optimize params that are required\n",
    "    params = [p for p in net.parameters() if p.requires_grad] # requires_grad 表示一个Tensor是否需要计算梯度, tensor可分为两类：叶子节点和非叶子节点\n",
    "    # 判断节点 requires_grad, 当打开 net.train() 的时候，就会有节点 requires_grad\n",
    "    optimizer = optim.Adam(params, lr=0.0001) # 优化器对象Optimizer，用来保存当前的状态，并能够根据计算得到的梯度来更新参数\n",
    "\n",
    "    epochs = 5\n",
    "    best_acc = 0.0\n",
    "    # save_path = './resNet34.pth'\n",
    "    save_path = './{}.pth'.format(model_name)\n",
    "    train_steps = len(train_loader) # \n",
    "    for epoch in range(epochs):\n",
    "        # train\n",
    "        net.train()\n",
    "        running_loss = 0.0\n",
    "        train_bar = tqdm(train_loader, file=sys.stdout) # train_loader 数据分批次后,,,\n",
    "        for step, data in enumerate(train_bar):\n",
    "            \n",
    "            images, labels = data\n",
    "            # images: # tensor([[[[-0.5938, -0.7993, -0.2171,  ..., -0.7479, -0.7650, -0.7650],\n",
    "                      # [-0.7650, -0.4739, -0.1657,  ..., -0.6794, -0.7137, -0.7308],\n",
    "                      # [-0.5938, -0.1828, -0.1999,  ..., -0.6794, -0.6794, -0.7137], ......\n",
    "            optimizer.zero_grad()\n",
    "            logits = net(images.to(device))\n",
    "            loss = loss_function(logits, labels.to(device))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            train_bar.desc = \"train epoch[{}/{}] loss:{:.3f}\".format(epoch + 1,\n",
    "                                                                     epochs,\n",
    "                                                                     loss)\n",
    "\n",
    "        # validate\n",
    "        # 和训练最大的区别就是没有反向传播\n",
    "        net.eval()\n",
    "        acc = 0.0  # accumulate accurate number / epoch\n",
    "        with torch.no_grad():\n",
    "            val_bar = tqdm(validate_loader, file=sys.stdout)\n",
    "            for val_data in val_bar:\n",
    "                val_images, val_labels = val_data\n",
    "                outputs = net(val_images.to(device))\n",
    "                # loss = loss_function(outputs, test_labels)\n",
    "                predict_y = torch.max(outputs, dim=1)[1] # 获取每一行最大值(每个对应所属类别的概率)的索引值 https://blog.csdn.net/pengchengliu/article/details/118928741\n",
    "\n",
    "                # 会自动选取概率最大的那个值\n",
    "                acc += torch.eq(predict_y, val_labels.to(device)).sum().item() # ......\n",
    "\n",
    "                val_bar.desc = \"valid epoch[{}/{}]\".format(epoch + 1, epochs)\n",
    "\n",
    "        val_accurate = acc / test_num\n",
    "        print('[epoch %d] train_loss: %.3f  val_accuracy: %.3f' %\n",
    "              (epoch + 1, running_loss / train_steps, val_accurate))\n",
    "\n",
    "        if val_accurate > best_acc:\n",
    "            best_acc = val_accurate\n",
    "            torch.save(net.state_dict(), save_path)\n",
    "\n",
    "    print('Finished Training')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "                        "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
